{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Tariq Faquih\"\n",
    "__copyright__ = \"Copyright 2020, Clinical Epidemiology Department, LUMC\"\n",
    "__credits__ = [\"Tariq Faquih\", \"Linda Nab\", \"Ype Jong\"]\n",
    "__license__ = \"MIT License\"\n",
    "__maintainer__ = \"Tariq Faquiih\"\n",
    "__email__ = \"t.o.faquih@lumc.nl\"\n",
    "__status__ = \"Development\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv , os , sys , datetime\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class objects send pubmed queries through the API and stores the output in json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class COVID:\n",
    " \n",
    "    def __init__(self , startD , endD):\n",
    "\n",
    "        #list of query terms to be used in the search_function\n",
    "\n",
    "        self.querydict = {'opioids':None , \n",
    "                 'Big Five':'(NEJM[journal] OR BMJ[journal] OR lancet[journal] OR nature[journal] OR JAMA[journal])', \n",
    "                 'Elderly':'elderly[TITLE]',\n",
    "                 'Clinical Trial':'clinical trial[Title/Abstract]' , \n",
    "                 'Italy':'italy[Title/Abstract]' , \n",
    "                 'Netherlands':'netherlands[Title/Abstract]' , \n",
    "                 'Case Control':'case control study' , \n",
    "                 'Epidemiology':'epidemiology' , \n",
    "                 'Mortality':'mortality', \n",
    "                 'Pregnant':'pregnant[TITLE]' }\n",
    "        \n",
    "        #json_file stores the proper json format to be used in the googlesheet\n",
    "        #dict_file stores the output in a dictionary to be loaded in later uses\n",
    "        json_file ='../jsonfiles/opioids.json'\n",
    "        dict_file ='../jsonfiles/opioids_dictionary4.json'\n",
    "\n",
    "        #read the stored dictionary file (dict_file) or create a new blank dictionary\n",
    "        if os.path.isfile(dict_file):\n",
    "            self.mainDict = json.load(open(dict_file))\n",
    "        else:\n",
    "            self.mainDict = {}\n",
    "        \n",
    "        #set counter for how many articles are added and create a list to store the log messages\n",
    "        self.NumNew = 0\n",
    "        self.Log = []\n",
    "        \n",
    "        #for each query term in the querylist, run the search function using the provideed start\n",
    "        #and end dates\n",
    "        for K in self.querydict.keys():\n",
    "            for DB in ('pubmed' , 'pmc'):\n",
    "                self.search_function(K , DB , startD , endD )\n",
    "            \n",
    "        #for X in querylist:\n",
    "        #    self.search_function(X , startD , endD )\n",
    "        \n",
    "        #add the total number of added articles to the log list\n",
    "        self.Log.append(self.NumNew)\n",
    "        \n",
    "        #Write the main json file\n",
    "        with open(json_file , 'w') as fp:   \n",
    "            Output=[]\n",
    "            for Key,Item in self.mainDict.items():\n",
    "                Output.append(Item)\n",
    "            json.dump(Output, fp)\n",
    "            \n",
    "        #Write the exact dict as json file (easily read by the script)\n",
    "        with open(dict_file , 'w') as fp:   \n",
    "            json.dump(self.mainDict, fp)\n",
    "        \n",
    "        with open('../logs/log_{}_{}.txt'.format(startD.replace('/' , '') , endD.replace('/' , '')) ,'w'  , newline='') as fp:\n",
    "            W = csv.writer(fp)\n",
    "            W.writerow(['Search results for range {} to {}'.format(startD , endD)])\n",
    "            W.writerow(['Number of Records Added: {}'.format(self.Log[-1])])\n",
    "            for Line in self.Log[:-1]:\n",
    "                W.writerow([Line])\n",
    "        \n",
    "\n",
    "    def search_function (self , MyTerms, DB , startD , endD):\n",
    "\n",
    "        Entrez.email = \"tariqf549@gmail.com\"\n",
    "        MainTerm = \"\"\"\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields]\"\"\"\n",
    "        #MainTerm = '\"COVID-19\"[All Fields]'\n",
    "        DateRange = '\"{}\"[PDAT] : \"{}\"[PDAT]'.format(startD , endD)\n",
    "        if MyTerms == 'opioids':\n",
    "            Query = MainTerm + ' AND ' + DateRange\n",
    "        else:\n",
    "            Query = MainTerm + ' AND ' + self.querydict[MyTerms] + ' AND ' + DateRange\n",
    "            \n",
    "        print(Query)\n",
    "        self.Log.append(Query)\n",
    "        search_results = Entrez.read(\n",
    "            Entrez.esearch(\n",
    "                db=DB, term=Query,  datetype=\"pdat\", usehistory=\"y\" , sort = 'relevance' \n",
    "            )\n",
    "        )\n",
    "        count = int(search_results[\"Count\"])\n",
    "        self.Log.append(\"Found %i results\" % count)\n",
    "        \n",
    "        print(\"Found %i results\" % count)\n",
    "\n",
    "        batch_size = 10\n",
    "        out_handle = open(\"../pubmed_results/opioids_{}_papers.txt\".format(MyTerms), \"w\" , encoding=\"utf-8\")\n",
    "        for start in range(0, count, batch_size):\n",
    "            end = min(count, start + batch_size)\n",
    "            print(\"Going to download record %i to %i\" % (start + 1, end))\n",
    "            self.Log.append(\"Going to download record %i to %i\" % (start + 1, end))\n",
    "            fetch_handle = Entrez.efetch(\n",
    "                db=DB,\n",
    "                rettype=\"medline\",\n",
    "                retmode=\"text\",\n",
    "                retstart=start,\n",
    "                retmax=batch_size,\n",
    "                webenv=search_results[\"WebEnv\"],\n",
    "                query_key=search_results[\"QueryKey\"],\n",
    "            )\n",
    "            data = fetch_handle.read()\n",
    "\n",
    "            dataresults = data.split('\\nPMID')[1:]\n",
    "            self.add2dict(dataresults , MyTerms)\n",
    "            #print(data)\n",
    "            fetch_handle.close()\n",
    "            out_handle.write(data)\n",
    "        out_handle.close()\n",
    "        \n",
    "    def FormatAbstract (self, AB):\n",
    "        Abstract = ''\n",
    "        if 'AB' in AB.keys():\n",
    "            Abstract = AB['AB']\n",
    "            tempAbs = Abstract.split(' ')\n",
    "            lastN=0\n",
    "            newabs = []\n",
    "            for N in range(30, len(tempAbs)+30, 30) :\n",
    "                newabs.append(' '.join(tempAbs[lastN:N]))\n",
    "                lastN= N\n",
    "                \n",
    "            Abstract = '\\n'.join(newabs)\n",
    "                \n",
    "        else: \n",
    "            Abstract = 'NA'\n",
    "            \n",
    "        return(Abstract)\n",
    "            \n",
    "    def add2dict(self , dataresults , Q):\n",
    "        for hit in dataresults:\n",
    "            m1 = 'PMID' + hit\n",
    "            parse_res = Medline.read(m1.split('\\n'))\n",
    "            if 'PMID' in parse_res.keys():\n",
    "                PMID = parse_res['PMID']\n",
    "                \n",
    "            elif 'PMCID' in parse_res.keys():\n",
    "                PMID = parse_res['PMCID']\n",
    "                \n",
    "            else: PMID = ''\n",
    "                \n",
    "            Tag = Q\n",
    "            if PMID in self.mainDict.keys():\n",
    "                print('PMID [{}] exists'.format(PMID))\n",
    "                self.Log.append('PMID exists')\n",
    "                if Q not in self.mainDict[PMID]['Tag']:\n",
    "                    self.mainDict[PMID]['Tag'] = self.mainDict[PMID]['Tag']+' '+Tag\n",
    "                    \n",
    "                if self.mainDict[PMID]['Abstract'] == 'NA':\n",
    "                    NewABS = self.FormatAbstract(parse_res)\n",
    "                    if NewABS != 'NA':\n",
    "                        self.mainDict[PMID]['Abstract'] = self.FormatAbstract(parse_res)\n",
    "                        print('Updated Abstract')\n",
    "                        self.Log.append('Updated Abstract')\n",
    "                        \n",
    "\n",
    "                    \n",
    "                continue\n",
    "            else:\n",
    "                Title = parse_res['TI']\n",
    "                \n",
    "                if 'JT' in parse_res.keys():\n",
    "                    JournalName  = parse_res['JT']\n",
    "                else: JournalName = ''\n",
    "                    \n",
    "                #Date of Publication [dp] - Date searching includes both print and electronic dates of publication. \n",
    "                #Searching for a single date does not include items when the electronic date of publication is after the print date.\n",
    "                if 'DP' in parse_res.keys():\n",
    "                    dateP  = parse_res['DP']\n",
    "                else: dateP = ''\n",
    "                \n",
    "                #The date the citation first entered PubMed. In PMC DEP is used instead\n",
    "                if 'EDAT' in parse_res.keys():\n",
    "                    dateC  = datetime.strptime(parse_res['EDAT'] , '%Y/%m/%d %H:%S')\n",
    "                    dateC = dateC.strftime(\"%Y%m%d\")\n",
    "                elif 'DEP' in parse_res.keys():\n",
    "                    dateC = parse_res['DEP']\n",
    "                else: dateC = ''\n",
    "\n",
    "                Abstract = self.FormatAbstract(parse_res)\n",
    "                \n",
    "                    \n",
    "                Link= 'https://www.ncbi.nlm.nih.gov/pubmed/{}'.format(PMID)   \n",
    "\n",
    "\n",
    "                self.mainDict[PMID] = {'PMID': PMID, 'Title':Title ,\n",
    "                                'JournalName':JournalName ,\n",
    "                                  'Date Added':dateC ,\n",
    "                                'Publication Date':dateP , \n",
    "                                'Abstract':Abstract , \n",
    "                                'Link':Link,\n",
    "                                'Tag':Tag   }\n",
    "                self.NumNew +=1\n",
    "                print('Added new PMID: {}'.format(PMID))\n",
    "                self.Log.append('Added new PMID: {}'.format(PMID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 7 results\n",
      "Going to download record 1 to 7\n",
      "Added new PMID: 32220099\n",
      "Added new PMID: 32221355\n",
      "Added new PMID: 32221867\n",
      "Added new PMID: 32219431\n",
      "Added new PMID: 32219415\n",
      "Added new PMID: 32220937\n",
      "Added new PMID: 32219920\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 4 results\n",
      "Going to download record 1 to 4\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND (NEJM[journal] OR BMJ[journal] OR lancet[journal] OR nature[journal] OR JAMA[journal]) AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND (NEJM[journal] OR BMJ[journal] OR lancet[journal] OR nature[journal] OR JAMA[journal]) AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND elderly[TITLE] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND elderly[TITLE] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND clinical trial[Title/Abstract] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND clinical trial[Title/Abstract] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND italy[Title/Abstract] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND italy[Title/Abstract] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND netherlands[Title/Abstract] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND netherlands[Title/Abstract] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND case control study AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND case control study AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 3 results\n",
      "Going to download record 1 to 3\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND epidemiology AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND epidemiology AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND mortality AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND mortality AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 2 results\n",
      "Going to download record 1 to 2\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND pregnant[TITLE] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n",
      "\"analgesics, opioid\"[Pharmacological Action] OR \"analgesics, opioid\"[MeSH Terms] OR (\"analgesics\"[All Fields] AND \"opioid\"[All Fields]) OR \"opioid analgesics\"[All Fields] OR \"opioids\"[All Fields] AND pregnant[TITLE] AND \"2020/03/27\"[PDAT] : \"2020/03/30\"[PDAT]\n",
      "Found 0 results\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/log_20200327_20200330.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d5e40c124b23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mStartDate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStartDate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%Y/%m/%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mCOVID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStartDate\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mToday\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-0c58d6608a2e>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, startD, endD)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logs/log_{}_{}.txt'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mendD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m  \u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m             \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Search results for range {} to {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartD\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mendD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/log_20200327_20200330.txt'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    Today = datetime.now()\n",
    "    StartDate = Today - timedelta(days=3)\n",
    "\n",
    "    Today = Today.strftime(\"%Y/%m/%d\")\n",
    "    StartDate = StartDate.strftime(\"%Y/%m/%d\")\n",
    "    \n",
    "    COVID(StartDate , Today )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COVID('2020/01/01' , '2020/03/30' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeTemplate():\n",
    "    headerslist = []\n",
    "    for H in ('PMID',\n",
    "              'Title',\n",
    "              'Link',\n",
    "                'JournalName',\n",
    "                'Date Added',\n",
    "                'Publication Date',\n",
    "                'Abstract',\n",
    "                'Tag'):\n",
    "        print(H)\n",
    "        headers = '=ImportJSON(\"https://raw.githubusercontent.com/tofaquih/coronaPubGet/master/results4.json\", \"/{}\", \"noInherit,noTruncate\",$A$1)'.format(H)\n",
    "        headerslist.append(headers)\n",
    "\n",
    "    headerslist\n",
    "    with open('../templates/template.csv' ,'w'  , newline='' ) as fp:\n",
    "        W = csv.writer(fp, delimiter=';')\n",
    "        W.writerow(headerslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMID\n",
      "Title\n",
      "Link\n",
      "JournalName\n",
      "Date Added\n",
      "Publication Date\n",
      "Abstract\n",
      "Tag\n"
     ]
    }
   ],
   "source": [
    "MakeTemplate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "query = '\"covid-19\"'\n",
    "url =  'https://scholar.google.com/scholar?start=0&q='+ query + '&hl=en&scisbd=1&as_sdt=1,5&as_vis=1&ie=UTF-8&oe=UTF-8&hl=en&btnG=Search'\n",
    "\n",
    "content = requests.get(url).text\n",
    "page = BeautifulSoup(content, 'html')\n",
    "results = []\n",
    "for entry in page.find_all(\"h3\", attrs={\"class\": \"gs_rt\"}):\n",
    "    results.append({\"title\": entry.a.text, \"url\": entry.a['href']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for entry in page.find_all(attrs={\"class\": \"gs_rs\"}):\n",
    "    maintext = entry.get_text()\n",
    "    D = maintext.split(' ')[0]\n",
    "    print(D)\n",
    "    print(entry.get_text())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
